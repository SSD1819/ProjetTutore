---
title: "Projet Cogmont"
author: "Azat, Lucas, Matthieu, Etienne"
date: "March 13, 2019"
output:
  pdf_document:
    toc: true
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

# Contexte / Sujet
Ce projet nous à été proposé par l'Institut des sciences cognitives - Marc Jeannerod spécialisé dans la neuroscience. L’UMR 5304 créée en 2007 est un des deux laboratoires de l’Institut des Sciences Cognitives – Marc Jeannerod. L'UMR 5304 est un laboratoire interdisciplinaire qui intègre l'expertise de chercheur des Sciences de la Vie (psychologie cognitive, neurosciences) et de médecine (pédo-psychiatrie, neuro-pédiatrie) avec celle de chercheur des Sciences Humaines et Sociales (linguistique computationelle et théorique et philosophie) pour étudier la nature et la spécificité de l'esprit humain.

## Les besoins d'un changement éducatif

 Le député et mathématicien Cédric Villani a publié un rapport pour renforcer l'apprentissage des mathématiques à l'école. Les élèves français sont aujourd'hui plus que médiocres dans cette discipline. Pourtant, jusqu'en 1985, l'enseignement des maths en France était reconnu comme l'un des meilleurs. Or, en décembre 2016, dernière édition de classement Pisa (Programme for international student assessment) la France a fini 24ème sur 72, en recule par rapport à la dernière édition. Pour mettre un terme à cette tendance inquiétante de la dégradation du niveau des élèves français en mathématiques, le gouvernement est à la recherche de nouvel pédagogie d'enseignement des mathématiques.

## Les pedagogies

\begin{description}
	\item[Pédagogie Montessori:] 

La pédagogie Montessori est une méthode d'éducation créée en 1907 par Maria Montessori.\newline
	La pédagogie se base sur trois principe:\newline
	-l’autodiscipline: les enfants sont libres de choisir l’activité qu’ils souhaitent faire parmi celles qui leur sont proposées.\newline
	-L’action en périphérique: Selon Maria Montessori, il est plus profitable d’agir sur son environnement plutôt que sur l’enfant lui-même (comme des classes multi-âge).

\item[Pédagogie "Traditionnelle":]

La pédagogie traditionnelle est celle du modèle transmissif. Selon le triangle pédagogique de Jean Houssaye, cette pédagogie privilégie la relation entre l'enseignant et le savoir. Autrement dit, l'enseignant expose un savoir sous forme de cours magistral, généralement suivi d'exercices ou/et de leçons à apprendre. L'élève doit intégrer et appliquer le savoir exposé par l'enseignant.


\end{description}

# Méthodologie
<!-- On parle au passé ? "nous avons vu ..." ou au futur ? "par la suite nous verrons ..."  -->
Afin de répondre au mieux à notre problématique nous avons fait le choix d'utiliser plusieurs méthodes statistiques différentes pour analyser nos données. Pour cela nous avons dans un premier temps utilisé une méthode qui permet de résumer l'information globale du jeu de données : l'analyse factorielle, et la classification ascendante hiérarchique (pour faire des regroupement de variables). Puis dans un but prédictif nous avons utilisé la regression logistique et les arbres de regressions. Plusieurs tests ont été fait en parallèles, comme celui du chi2, de student.. 

## Analyse factorielle

La méthode d'analyse factorielle que nous avons utilisé ici est l'analyse des correspondances multiples (ACM), qui est une méthode de synthétisations du nombre de dimensions pour les données qualitative. Cela nous permet d'appréhender plus rapidement le jeu de donnée, et avoir une première idée de ce qui diffèrent les individus entre eux (ou ce qui les rapproche).
L'ACM permet dans un nuage à N dimension, en cherchant les plans orthogonaux qui maximisent la variance entre les individus, à résumer celles ci en 4 voir 5 dimensions. 
l'ACM a été réalisée sur les réponses aux questions en variables actives (celles qui définissent le placement des individus sur le graphe) avec les variables portant sur la pédagogie, la question 1, et l'âge en illustratives (ajoutée après le placement des individus sur le graphe).

## Regression Logistique

Notre problématique étant de voir s'il existe un lien entre la façon d'enseigner et les réponses au test, nous avons voulu essayer de prédire la méthode d'enseignement à l'aide des réponses des élèves avec la regression logistique. Cette méthode permet de modéliser une classification, à l'aide notamment de l'odds ratio <!-- partie à verifier --> 

## Classification Ascendante Hiérachique

N'ayant aucune information au préalable sur le thème des questions, leur regroupement...etc Mais sachant que certaines questions faisaient appellent aux mêmes compétences. Nous avons utilisé une variante de la classification ascendante hiérarchique (CAH) afin de partitionner nos variables.

## Arbre de regression 

L'arbre de régression est une technique d'apprentissage supervisé, qui permet en analysant un grand nombre de données, de prédire une variable à expliquer. Ils sont beaucoup utilisés dans le domaine du marketing, et plus récemment dans le domaine du machine learning (apprentissage automatique).
Dans un premier temps il s'agit d'exprimer la variable à expliquer en fonction d'un maximum de variables explicative, puis d'élaguer l'arbre afin de minimiser l'erreur, soit l'écart entre la valeur prédite et la valeur réelle. Cela revient donc à faire une régression logistique sur les données, puis d'appliquer l'algorithme de construction d'arbre à partir des résultats.

# Traitement des données
## Présentation des données de départ
\section{Importation des données}
Notre jeu de données est composé de trois fichiers Excel (.xlsx), avec les résultats de chaque promotion au test cognitif européen.
    \begin{description}
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2015/2016.
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2016/2017.
    \item[MathsJetons\_2016-2017.xlsx :] Pour l'année 2017/2018.
    \end{description}
    Chaque jeu de données représente les résultats questions par questions (en comptant les sous-questions) des élèves  ainsi que leurs catégories pédagogiques et des informations telles que l'encadrant, le niveau scolaire, la langue natale, l'âge, le type de classe (mélangé entre plusieurs section ou pas), l'année de passage du test et leur école.
    Il y à 10 questions divisées en sous questions, ce qui fait un total de 34 réponses. Chaque question est indépendante et pour répondre à la sous question suivante il faut une bonne réponse à la sous-question précédente, sauf pour la question 4, toutes ses sous-questions sont indépendantes. Une bonne réponse correspond à un 1 et une mauvaise réponse à un 0, sauf pour la réponse à la question 1 qui est la valeur de comptage maximale de l'enfant.
    Ici les élèves viennent tous de l'école Ambroise Croizat à Vault-en-Velin. 
    
## Nettoyage des données 
###	Présence de NAs ...
## Ajustement des variables
# Analyse exploratoire
##	Univariée
##	Multivariée
##	Recherche de regroupement de variables (cah sur les variables)
# Recherche de différence significative entre p1 et p2
##	Regression logistique 
##	Tests sur les différentes réponses

Creation of dataframes containing only respectively P1 and P2 
```{r}
dataPropreP1<-subset(dataPropre, Pedagogie == "P1")
dataPropreP2<-subset(dataPropre, Pedagogie == "P2")
```

```{r}
# T1 t-test
tt<-t.test(dataPropreP1$T1, dataPropreP2$T1)

# the rest - proportion tests
d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "two.sided", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=tt$p.value
rownames(d)[29]<-"T1"

### Final result of p-values (two.sided) ###
print(d)

# rows where p-value is smaller than 0.05
subset(d, d[,1] < 0.05)
```

Trying with less option
```{r}
d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "less", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=t.test(dataPropreP1$T1, dataPropreP2$T1)$p.value
rownames(d)[29]<-"T1"

### Final result of p-values (less) ###
subset(d, d[,1] < 0.05) 
```

No new results

Trying with greater option

```{r}
d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "greater", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=t.test(dataPropreP1$T1, dataPropreP2$T1)$p.value
rownames(d)[29]<-"T1"

### Final result of p-values (greater) ###
subset(d, d[,1] < 0.05) 
```
ONLY T81 added

Testing with new variables (two.sided)

```{r}
don.groupeP1<-subset(don.groupe, Pedagogie == "P1")
don.groupeP2<-subset(don.groupe, Pedagogie == "P2")

m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "two.sided", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela)
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils)
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet)
df4  = tt$p.value

df=data.frame(x=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-values/prop.test - New Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

Testing with greater option

```{r}
m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "greater", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela, alternative = "greater")
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils, alternative = "greater")
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet, alternative = "greater")
df4  = tt$p.value

df=data.frame(prop.i=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-values/prop.test - New Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

Testing with less option

```{r}
m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "less", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela, alternative = "less")
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils, alternative = "less")
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet, alternative = "less")
df4  = tt$p.value

df=data.frame(prop.i=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-values/prop.test - New Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

Visualisation of significantly different data

```{r}
# T72
T72 <- rbind(prop.table(table(dataPropreP1$T72)),prop.table(table(dataPropreP2$T72)))
barplot(T72, beside = T, col = c("blue", "green"), main="T72 reponses: P1>P2",
        legend.text =c("P1","P2"),args.legend = list(x = "topright"))

# T81
T81 <- rbind(prop.table(table(dataPropreP1$T81)),prop.table(table(dataPropreP2$T81)))
barplot(T81, beside = T, col = c("blue", "green"), main="T81 reponses: P1<P2",
        legend.text =c("P1","P2"),args.legend = list(x = "top"))

# T87
T87 <- rbind(prop.table(table(dataPropreP1$T87)),prop.table(table(dataPropreP2$T87)))
barplot(T87, beside = T, col = c("blue", "green"), main="T87 reponses: P1<P2",
        legend.text =c("P1","P2"),args.legend = list(x = "top"))

# T88
T88 <- rbind(prop.table(table(dataPropreP1$T88)),prop.table(table(dataPropreP2$T88)))
barplot(T88, beside = T, col = c("blue", "green"), main="T88 reponses: P1<P2",
        legend.text =c("P1","P2"),args.legend = list(x = "top"))

# T89
T89 <- rbind(prop.table(table(dataPropreP1$T89)),prop.table(table(dataPropreP2$T89)))
barplot(T89, beside = T, col = c("blue", "green"), main="T89 reponses: P1<P2",
        legend.text =c("P1","P2"),args.legend = list(x = "top"))

# audela
audela <- rbind(prop.table(table(don.groupeP1$audela)),prop.table(table(don.groupeP2$audela)))
barplot(audela, beside = T, col = c("blue", "green"), main="audela: P1<P2",
        legend.text =c("P1","P2"),args.legend = list(x = "topright"))
```




##	Arbre de regression ?
# Conclusion
	
	


