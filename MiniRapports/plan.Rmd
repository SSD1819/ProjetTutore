---
title: "Projet Cogmont"
author: "Azat, Lucas, Matthieu, Etienne"
date: "March 13, 2019"
output:
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, include = FALSE)
```

# Introduction

# Contexte / Sujet
Ce projet nous à été proposé par l'Institut des sciences cognitives - Marc Jeannerod spécialisé dans la neuroscience. L’UMR 5304 créée en 2007 est un des deux laboratoires de l’Institut des Sciences Cognitives – Marc Jeannerod. L'UMR 5304 est un laboratoire interdisciplinaire qui intègre l'expertise de chercheur des Sciences de la Vie (psychologie cognitive, neurosciences) et de médecine (pédo-psychiatrie, neuro-pédiatrie) avec celle de chercheur des Sciences Humaines et Sociales (linguistique computationelle et théorique et philosophie) pour étudier la nature et la spécificité de l'esprit humain.

## Les besoins d'un changement éducatif

 Le député et mathématicien Cédric Villani a publié un rapport pour renforcer l'apprentissage des mathématiques à l'école. Les élèves français sont aujourd'hui plus que médiocres dans cette discipline. Pourtant, jusqu'en 1985, l'enseignement des maths en France était reconnu comme l'un des meilleurs. Or, en décembre 2016, dernière édition de classement Pisa (Programme for international student assessment) la France a fini 24ème sur 72, en recule par rapport à la dernière édition. Pour mettre un terme à cette tendance inquiétante de la dégradation du niveau des élèves français en mathématiques, le gouvernement est à la recherche de nouvel pédagogie d'enseignement des mathématiques.

## Les pedagogies

\begin{description}
	\item[Pédagogie Montessori:] 

La pédagogie Montessori est une méthode d'éducation créée en 1907 par Maria Montessori.\newline
	La pédagogie se base sur trois principe:\newline
	-l’autodiscipline: les enfants sont libres de choisir l’activité qu’ils souhaitent faire parmi celles qui leur sont proposées.\newline
	-L’action en périphérique: Selon Maria Montessori, il est plus profitable d’agir sur son environnement plutôt que sur l’enfant lui-même (comme des classes multi-âge).

\item[Pédagogie "Traditionnelle":]

La pédagogie traditionnelle est celle du modèle transmissif. Selon le triangle pédagogique de Jean Houssaye, cette pédagogie privilégie la relation entre l'enseignant et le savoir. Autrement dit, l'enseignant expose un savoir sous forme de cours magistral, généralement suivi d'exercices ou/et de leçons à apprendre. L'élève doit intégrer et appliquer le savoir exposé par l'enseignant.


\end{description}

## Présentation des données de départ
\section{Importation des données}
Notre jeu de données est composé de trois fichiers Excel (.xlsx), avec les résultats de chaque promotion au test cognitif européen.
    \begin{description}
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2015/2016.
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2016/2017.
    \item[MathsJetons\_2016-2017.xlsx :] Pour l'année 2017/2018.
    \end{description}
    Chaque jeu de données représente les résultats questions par questions (en comptant les sous-questions) des élèves  ainsi que leurs catégories pédagogiques et des informations telles que l'encadrant, le niveau scolaire, la langue natale, l'âge, le type de classe (mélangé entre plusieurs section ou pas), l'année de passage du test et leur école.
    Il y à 10 questions divisées en sous questions, ce qui fait un total de 34 réponses. Chaque question est indépendante et pour répondre à la sous question suivante il faut une bonne réponse à la sous-question précédente, sauf pour la question 4, toutes ses sous-questions sont indépendantes. Une bonne réponse correspond à un 1 et une mauvaise réponse à un 0, sauf pour la réponse à la question 1 qui est la valeur de comptage maximale de l'enfant.
    Ici les élèves viennent tous de l'école Ambroise Croizat à Vault-en-Velin. 

## Nettoyage des données 

Les données ayant déjà été travaillées l'année dernière le travail nécessaire en datamanagement n'a pas été excessif. Il nous a fallut tout de même renommer certaines variables pour les rendre plus lisibles, supprimer certaines questions car elles n'avaient été posées qu'à certaines classes... 
Les questions étant posées de manière à ce qu'au sein d'une même tache, il faille réussir les questions dans l'ordre pour passer à celles plus dures nous avions beaucoup de NA dès qu'une question est dûre. Nous avons donc décidé de changer ces NA et les considérer comme une question que l'élève n'aurait pas réussit. Et pour ne pas passer à coté de l'information : "n'a pu aller plus loin", nous avons crée deux jeux de données : un vectoriel, un composé de scores correspondant à la somme des questions au sein d'une même tache.
<!--
Importation des données

```{r}
#Librairies nécéssaires
require(readxl)
require(dplyr)
require(stringr)

load("../.RData") #to be deleted after the new variables sheet copy

#Moyenne section 2015/2016
mathsJetons_2015_2016 <- read_excel("../MathsJetons_2015-2016.xlsx") %>% data.frame(row.names = 2)
don1516 <- mathsJetons_2015_2016[mathsJetons_2015_2016$Niveau == "MSM",]

#Moyenne section 2016/2017
mathsJetons_2016_2017 <- read_excel("../MathsJetons_2016-2017.xlsx",sheet = "QualiSsAtyp")
mathsJetons_2016_2017 <- mathsJetons_2016_2017[is.na(mathsJetons_2016_2017[,2]) == FALSE,] %>% data.frame(row.names = 2)
don1617 <- mathsJetons_2016_2017[mathsJetons_2016_2017$Niveau == "MSM",]

#Moyenne section 2017/2018
mathsJetons_2017_2018 <- read_excel("../MathsJetons_2017-2018.xlsx") %>% data.frame(row.names = 2)
don1718<-mathsJetons_2017_2018[mathsJetons_2017_2018$Niveau == "MSM",]
```

Changement de nom des colonnes (pas identique sur don1516 et les autres)

```{r}
colnames(don1516)[c(1,9,13,46,47,48)] <- c("Experimentateur","Lateralite","age","T111.TOTAL","T112.TOTAL","T113.TOTAL")
colnames(don1617)[c(1,9,13,46,47,48)] <- c("Experimentateur","Lateralite","age","T111.TOTAL","T112.TOTAL","T113.TOTAL")
colnames(don1718)[c(1,9,13,46,47,48)] <- c("Experimentateur","Lateralite","age","T111.TOTAL","T112.TOTAL","T113.TOTAL")
```

Ensemble des moyennes sections 2015/2016/2017/2018

```{r}
dataMoySec<-cbind(rbind(don1516,don1617,don1718),c(rep("15/16",length(don1516[,1])),rep("16/17",length(don1617[,1])),rep("17/18",length(don1718[,1]))))
colnames(dataMoySec)[49]<-"annee.scolaire"
```

Recherche des variables à une seule modalité

```{r}

NbMod<-function(x){
  return(length(table(x)))
}
pos1<-which(apply(X=dataMoySec,MARGIN=2,FUN=NbMod)==1)

#Suppression des variables qui n'ont qu'une modalité et ne servent à rien ("Ecole" et "Niveau")
dataPropre<-dataMoySec[,-pos1]

TabMod<-function(x){
  return(table(x))
}

apply(X=dataPropre,MARGIN=2,FUN=TabMod)
```

Correction des modalités de la variable **Type.de.classe** et **Langues**

```{r}
dataPropre$Type.de.classe<-str_to_lower(dataPropre$Type.de.classe)
dataPropre$Type.de.classe<-sub("grands","grand",dataPropre$Type.de.classe)
dataPropre$Type.de.classe<-sub("grand","grands",dataPropre$Type.de.classe)

dataPropre$Langues<-str_to_lower(dataPropre$Langues)
dataPropre$Langues<-sub("/","et",dataPropre$Langues)

#Suppression des variables T11 et T9
dataPropre<-dataPropre[,-c(42:46)]
```

Stats univariées sur le jeu de données (table)
```{r}
apply(X=dataPropre,MARGIN=2,FUN=TabMod)
```

Changement des types de variables

```{r}
#Changement des variables en facteurs
nom<-c("Experimentateur","Pédagogie","Classe","Type.de.classe",
       "Sexe..F.ou.M.","Langues","Lateralite",
       "Classe.d.age",
       "T21.TOTAL","T22.TOTAL","T23.TOTAL","T31TOTAL","T32.TOTAL",
       "T41a.TOTAL","T41b.TOTAL","T41cTOTAL","T41d.TOTAL","T42a.TOTAL",
       "T42b.TOTAL","T42c.TOTAL","T42d.TOTAL","T51.TOTAL","T52.TOTAL","T61.TOTAL",
       "T62TOTAL","T71.TOTAL","T72TOTAL","T81.TOTAL","T82.TOTAL","T83.TOTAL","T84.TOTAL",
       "T85.TOTAL","T86.TOTAL","T87.TOTAL","T88.TOTAL","T89.TOTAL","annee.scolaire")


for (i in 1:ncol(dataPropre)){
  if (colnames(dataPropre)[i]%in%nom ){
    dataPropre[,i]<-as.factor(dataPropre[,i])
  }
}

#Question 1 comme variable numérique
dataPropre$T1.Réponse<-as.numeric(dataPropre$T1.Réponse)
```

Re-stats univariées sur datapropre

```{r}
summary(dataPropre)
```

Mettre en forme le dataframe

```{r}
#Remplacement du nom de la variable "Type.de.classe" par "type.de.classe"
names(dataPropre)[which(names(dataPropre)=="Type.de.classe")]<-"type.de.classe"

#On remplace les na des questions par "0"
posQ<-which(substr(names(dataPropre),1,1)=="T")
questions<-dataPropre[,posQ]
questions[is.na(questions)]<-"0"

#Vérification qu'il n'y ait pas l'incohérence 0 -> 1 (sauf pour les Q4)
vecAnte<-t(apply(questions[,c(2:28)],1,as.numeric))
colnames(vecAnte)<-names(questions[,c(2:28)])
vecPost<-t(apply(questions[,c(3:29)],1,as.numeric))
colnames(vecPost)<-names(questions[,c(3:29)])
vecDiff<-vecPost-vecAnte

#Il existe des incohérences, on les recherche
#On enlève d'abord les questions qui ne peuvent pas avoir d'incohérence
incoher<-vecDiff[,which(as.numeric(substr(names(questions[,3:29]),3,3))>1 & as.numeric(substr(names(questions[,3:29]),2,2))!=4 & as.numeric(substr(names(questions[,3:29]),2,2))!=8)]

#On récupère ensuite les lignes et colonnes comprtant 1 à la diff entre post et ante
incoher2<-incoher[which(apply(incoher,1,max)==1),which(apply(incoher,2,max)==1)]

#Remplacement des questions avec NA par questions avec 0 dans datapropre
dataPropre[,posQ]<-questions

#Correction de la question 2 (enfants 0->1 devient 1->1)
dataPropre$T21.TOTAL[which(dataPropre$T21.TOTAL=="0" & dataPropre$T22.TOTAL=="1")]<-"1"
```

Création du jeu de données où les résultats des questions sont des vecteurs

```{r}

T1<-questions[,1]
T2<-paste(questions[,2],questions[,3],questions[,4],sep="")
T3<-paste(questions[,5],questions[,6],sep="")
T41<-paste(questions[,7],questions[,8],questions[,9],questions[,10],sep="")
T42<-paste(questions[,11],questions[,12],questions[,13],questions[,14],sep="")
T5<-paste(questions[,15],questions[,16],sep="")
questionsVec<-cbind(T1,T2,T3,T41,T42,T5,questions[,17:29])
dataVec<-cbind(dataPropre[,-posQ],questionsVec)
```

Création du jeu de données où les résultats des question sont des sommes

```{r}
questionsNum<-apply(questions,2,as.numeric)
T1<-questionsNum[,1]
T2<-questionsNum[,2]+questionsNum[,3]+questionsNum[,4]
T3<-questionsNum[,5]+questionsNum[,6]
T41<-paste(questions[,7],questions[,8],questions[,9],questions[,10],sep="")
T42<-paste(questions[,11],questions[,12],questions[,13],questions[,14],sep="")
T5<-questionsNum[,15]+questionsNum[,16]
questionsSum<-data.frame(T1,T2,T3,T41,T42,T5,questionsNum[,17:29])
dataSum<-cbind(dataPropre[,-posQ],questionsSum)
```


Changement du nom des colonnes qui ne sont pas très propres

```{r}
names(dataPropre)[c(2,4,5,8,9:13,42)]<-c(
  "Pedagogie",
  "TypeClasse",
  "Sexe",
  "DateNaissance",
  "DateEval",
  "AgeChar",
  "AgeNum",
  "AgeInt",
  "T1",
  "AnneeScolaire"
)

names(dataVec)[c(2,4,5,8,9:13)]<-c(
  "Pedagogie",
  "TypeClasse",
  "Sexe",
  "DateNaissance",
  "DateEval",
  "AgeChar",
  "AgeNum",
  "AgeInt",
  "AnneeScolaire"
)

names(dataSum)[c(2,4,5,8,9:13)]<-c(
  "Pedagogie",
  "TypeClasse",
  "Sexe",
  "DateNaissance",
  "DateEval",
  "AgeChar",
  "AgeNum",
  "AgeInt",
  "AnneeScolaire"
)

#Suppression ". TOTAL"
names(dataPropre)<-sub(".","",names(dataPropre),fixed=TRUE)
names(dataPropre)<-sub("TOTAL","",names(dataPropre),fixed=TRUE)
names(dataPropre)<-sub("Total","",names(dataPropre),fixed=TRUE)
names(dataVec)<-sub(".","",names(dataVec),fixed=TRUE)
names(dataVec)<-sub("TOTAL","",names(dataVec),fixed=TRUE)
names(dataSum)<-sub(".","",names(dataSum),fixed=TRUE)
names(dataSum)<-sub("TOTAL","",names(dataSum),fixed=TRUE)
```


Regroupement des quesions

```{r}
#Regroupement des quesions T8.123 et T8.456789 dans le jeu dataVec
cols.123<-c(names(dataVec[,24:26]))
cols.456789<-c(names(dataVec[,27:32]))
T8.123<-apply(dataVec[,cols.123],1, paste , collapse = "" )
T8.456789<-apply(dataVec[,cols.456789],1, paste , collapse = " " )
dataVec<-cbind(dataVec, T8.123, T8.456789)
dataVec <- dataVec[,!(names(dataVec) %in% c(cols.123,cols.456789 )) ]

#Regroupement des quesions T8.123 et T8.456789 dans le jeu dataSum
T8.123<-dataSum[,"T81"]+dataSum[,"T82"]+dataSum[,"T83"]
T8.456789<-dataSum[,"T84"]+dataSum[,"T85"]+dataSum[,"T86"]+dataSum[,"T87"]+dataSum[,"T88"]+dataSum[,"T89"]
dataSum<-cbind(dataSum, T8.123, "T8.456789"=T8.456789)
dataSum<-dataSum[,!(names(dataSum) %in% c(cols.123,cols.456789 )) ]

```
-->
## Recodage des variables


# Méthodologie
<!-- On parle au passé ? "nous avons vu ..." ou au futur ? "par la suite nous verrons ..."  -->
Afin de répondre au mieux à notre problématique nous avons fait le choix d'utiliser plusieurs méthodes statistiques différentes pour analyser nos données. Pour cela nous avons dans un premier temps utilisé une méthode qui permet de résumer l'information globale du jeu de données : l'analyse factorielle, et la classification ascendante hiérarchique (pour faire des regroupement de variables). Puis dans un but prédictif nous avons utilisé la regression logistique et les arbres de regressions. Plusieurs tests ont été fait en parallèles, comme celui du chi2, de student.. 

## Analyse factorielle

Les méthodes d'analyse factorielle que nous avons utilisé ici sont l'analyse des correspondances multiples (ACM) et l'analyse en composantes principales (ACP), qui sont des méthodes de synthétisations du nombre de dimensions pour les données qualitative et quantitatives. Cela nous permet d'appréhender plus rapidement le jeu de donnée, et avoir une première idée de ce qui diffèrent les individus entre eux (ou ce qui les rapproche).
L'ACM permet dans un nuage à N dimension, en cherchant les plans orthogonaux qui maximisent la variance entre les individus, à résumer celles ci en 4 voir 5 dimensions. 
l'ACM a été réalisée sur les données vectorisées, celles ci ont été prises comme variables actives (celles qui définissent le placement des individus sur le graphe) et les variables portant sur la pédagogie, la question 1, et l'âge en illustratives (ajoutée après le placement des individus sur le graphe).
Le principe était le même pour l'ACP qui a été faite ensuite.

## Regression Logistique

Notre problématique étant de voir s'il existe un lien entre la façon d'enseigner et les réponses au test, nous avons voulu essayer de prédire la méthode d'enseignement à l'aide des réponses des élèves avec la regression logistique. Cette méthode permet de modéliser une classification, à l'aide notamment de l'odds ratio <!-- partie à verifier --> 

## Classification Ascendante Hiérachique

N'ayant aucune information au préalable sur le thème des questions, leur regroupement...etc Mais sachant que certaines questions faisaient appellent aux mêmes compétences. Nous avons utilisé une variante de la classification ascendante hiérarchique (CAH) afin de partitionner nos variables.

## Arbre de regression 

L'arbre de régression est une technique d'apprentissage supervisé, qui permet en analysant un grand nombre de données, de prédire une variable à expliquer. Ils sont beaucoup utilisés dans le domaine du marketing, et plus récemment dans le domaine du machine learning (apprentissage automatique).
Dans un premier temps il s'agit d'exprimer la variable à expliquer en fonction d'un maximum de variables explicative, puis d'élaguer l'arbre afin de minimiser l'erreur, soit l'écart entre la valeur prédite et la valeur réelle. Cela revient donc à faire une régression logistique sur les données, puis d'appliquer l'algorithme de construction d'arbre à partir des résultats.

# Analyse exploratoire
##	Univariée

##	Multivariée
Afin de traiter l'information présente dans le jeu de données de la meilleure façon, nous avons procédé à 2 analyses multivariées : 1 sur le jeu de données qualitatif sous forme de vecteurs, et 1 sur le jeu de données quantitatif sous forme de scores.
###ACM

```{r}
### ACM sur data vectorielle
if (!require("FactoMineR")) install.packages("FactoMineR")
require(FactoMineR)
if (!require("factoextra")) install.packages("factoextra")
require(factoextra)
if (!require("dplyr")) install.packages("dplyr")
require(dplyr) 

colnames(dataVec)

noms<-colnames(dataVec[,c(2,14,11,15:25)])
valqualis<-dataVec[,noms]
summary(valqualis)

valqualis$T1<- as.factor(valqualis$T1)
valqualis$AgeNum<- as.factor(valqualis$AgeNum)

res.mca<-MCA(valqualis,quali.sup = 1:3)

#9.2% information

dimdesc(res.mca)
summary(res.mca)

plot.MCA(res.mca,invisible = "ind",cex=0.7,selectMod =  "contrib 15")
plot.MCA(res.mca,invisible = "ind",cex=0.7)

res.hcpc<-HCPC(res.mca,nb.clust = 3)
res.hcpc$desc.var
plot.HCPC(res.hcpc,choice = "bar")

valqualisP1<-filter(valqualis, Pedagogie == "P1")
valqualisP1<-valqualisP1[,-1]

valqualisP2<-filter(valqualis, Pedagogie == "P2")
valqualisP2<-valqualisP1[,-1]

par(mfrow=c(1,2))
res.mca1<-MCA(valqualisP1,quali.sup = 1:2)
res.mca2<-MCA(valqualisP2,quali.sup = 1:2)
```

###ACP

Réalisation de 3 ACP : 
1 sur le jeu de données avec les scores sans les q4 (car non numériques)
1 sur le jeu de données avec seulement deux q8 (car corrélées)
1 sur le jeu de données avec l'essentiel des q4 et des q8

##JDD 1
```{r}
require(FactoMineR)
require(factoextra)
# summary(dataSum)

#soit acp sur tout sauf la Q4 car vectorielle
#soit afm
# colnames(dataSum)
noms<-c("Pedagogie", "T1","T2","T3",
        "T5","T61","T62","T71","T72","T81",
        "T82","T83","T84","T85","T86","T87",
        "T88","T89")
valquanti<-dataSum[,noms]
valquanti[,2:length(valquanti)]<-scale(valquanti[,2:length(valquanti)])
res.pca<-PCA(valquanti,quali.sup = 1,graph = FALSE)
plot.PCA(res.pca,choix = "var",select = "contrib 8")

```
Les questions 8 ressortent le plus (puis la 3), comme dans les précédentes analyses : cela nous pousse à voir la matrice des corrélations
Seulement 60% de l'info sur les 4 premières dimensions
```{r}
plot.PCA(res.pca,choix = "var",select = "contrib 8",axes = c(3,4)) #Dim 3 > T_72
# summary(res.pca)
```
Dimension 3 expliquée par la T72.

##Matrice des corrélations
```{r}
# install.packages("corrplot")
library(corrplot)
summary(dataPropre)
m.cor<-cor(sapply(dataPropre[,13:ncol(dataPropre)],as.numeric))#matrice des corrélations pour les questions 8
corrplot(m.cor,method = "circle")
```
Grosse corrélation entre les 8* : donc ACP biaisée (et légère sur les q4 mais suffisante pour biaiser l'analyse)
Etonnemment la T1 ne ressort pas comme grosse contrib

##JDD 2
```{r}
##Nouvelle PCA sans les T8 super correlées entre elles (que T81 et T82 car ce sont les moins correlées)
valquanti1<-valquanti[,-c(12:18)]
summary(valquanti1)
res.pca1<-PCA(valquanti1,quali.sup = 1,graph = FALSE)
plot.PCA(res.pca1,axes = c(1,2),choix = "ind")

```
Aucune démarcation entre P1 et P2 sur la première dimension.

```{r}
plot.PCA(res.pca1,axes = c(1,2),choix = "var",select = "cos2 5")
```
T2 / T3 sont proches et ont un cos2 élevé : un gros score en T2 implique un gros score en T3
La dimension 1 porte sur les T2 et T3
La deuxième dimension porte sur la T62

```{r}
plot.PCA(res.pca1,axes = c(3,4),choix = "var")
```
La dimension 3 porte sur la T72
La dimension 4 porte sur la T5
En conséquent nous avons quasi 1 variable / axe l'utilité de l'acp peut être remise en question

##JDD 2
```{r}
#Ajout d'une acp avec les q4 de datapropre (seulement celles les plus corrélées aux autres)
valquanti2<-cbind(valquanti1,
                  apply(dataPropre[,c("T41a","T41c","T41d")],2,as.numeric))
res.pca1<-PCA(valquanti2,quali.sup = 1,graph = FALSE)
plot.PCA(res.pca1,axes = c(1,2),choix = "ind")
```
A nouveau aucune démarcation entre P1 et P2

```{r}
plot.PCA(res.pca1,axes = c(1,2),choix = "var",select = "cos2 5")
```
La dimension 1 porte sur les questions T2 et 3
La dimension 2 porte sur les questions T41c/d (très corrélé alors qu'on ne le voit pas dans le cor) et T61

```{r}
plot.PCA(res.pca1,axes = c(3,4),choix = "var",select = "cos2 5")
```
Les dimensions 3 et 4 portent sur la question T72


L'ACP permet donc dans les 3 cas d'observer des différences au sein de la population, mais qui n'est pas significative avec la pédagogie suivit par les individus.



##	Recherche de regroupement de variables (cah sur les variables)
# Recherche de différence significative entre p1 et p2
##	Regression logistique 
##	Tests sur les différentes réponses

```{r}
# Création de dataframes contenant uniquement les resulatats P1 et P2 respectivement

dataPropreP1 <- subset(dataPropre, Pedagogie == "P1")
dataPropreP2 <- subset(dataPropre, Pedagogie == "P2")
```

### Tests

```{r}
# T1 - t-test

tt<-t.test(dataPropreP1$T1, dataPropreP2$T1, alternative = "two.sided")

# Les autres - tests de proportions

d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "two.sided", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=tt$p.value
rownames(d)[29]<-"T1"

# Résultat final des p-valeurs (two.sided)
print(d)

# les p-valeurs inférieure à 0,05
subset(d, d[,1] < 0.05) 
```

Doce, les tests montrent que dans les réponses à certaines questions `r subset(d, d[,1] < 0.05)`, il existe des différences significatives entre deux pédagogies. Maintenant, il faut préciser à quelle pédagogie est favorable la différence.

```{r}
### Option "less" ###

tt<-t.test(dataPropreP1$T1, dataPropreP2$T1, alternative = "less")

d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "less", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=tt$p.value
rownames(d)[29]<-"T1"

# Résultat final des p-valeurs ("less")
print(d)

# les p-valeurs inférieure à 0,05
subset(d, d[,1] < 0.05) 
```

Ainsi, le test nous montre que pour une des questions trouvées lors du premier test - T72 les résultats de P2 sont meilleurs que ceux de P1.

```{r}
### Option "greater"  ###

tt<-t.test(dataPropreP1$T1, dataPropreP2$T1, alternative = "greater")

d=data.frame(x=rep(0,27))
for (i in 14:41){
  mat.i<-cbind(matrix(table(dataPropreP1[,i])), matrix(table(dataPropreP2[,i])))
  prop.i<-prop.test(mat.i, alternative = "greater", correct = FALSE)
  d[i,] = prop.i$p.value
}

d<-data.frame(d[-c(1:13),])
row.names(d)<-colnames(dataPropre[,14:41])
colnames(d)<-c("p-values of prop.test")
d[29,]=tt$p.value
rownames(d)[29]<-"T1"

# Résultat final des p-valeurs ("greater")
print(d)

# les p-valeurs inférieure à 0,05
subset(d, d[,1] < 0.05) 
```

Dans le test "greater"(supérieur), en plus des 3 autres questions restent, nous avons ajouté T81. Le test montre que, pour les questions sélectionnés, les résultats de P1 sont meilleurs que ceux de P2.

### Tests avec nouvelles variables

```{r}
don.groupeP1<-subset(don.groupe, Pedagogie == "P1")
don.groupeP2<-subset(don.groupe, Pedagogie == "P2")

m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "two.sided", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela)
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils)
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet)
df4  = tt$p.value

df=data.frame(x=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-values/prop.test - New Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

En ce qui concerne les tests sur les nouvelles variables: le test de la différence générale ("two.sided") montre que les résultats de la variable audela pour P1 et P2 sont significativement différents. Donc, nous devrions aller plus loin pour trouver la meilleure pédagogie pour cela.

```{r}
### Option "greater" ###

m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "greater", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela, alternative = "greater")
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils, alternative = "greater")
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet, alternative = "greater")
df4  = tt$p.value

df=data.frame(prop.i=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-valeurs/less - Nouvelles Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

```{r}
### Option "less" ###

m<-cbind(matrix(table(don.groupeP1[,2])), matrix(table(don.groupeP2[,2])))
pt<-prop.test(m, alternative = "less", correct = FALSE)
df1 = pt$p.value
tt<-t.test(don.groupeP1$audela, don.groupeP2$audela, alternative = "less")
df2  = tt$p.value
tt<-t.test(don.groupeP1$outils, don.groupeP2$outils, alternative = "less")
df3 = tt$p.value
tt<-t.test(don.groupeP1$objet, don.groupeP2$objet, alternative = "less")
df4  = tt$p.value

df=data.frame(prop.i=rep(0,4))
df[1,]=df1
df[2,]=df2
df[3,]=df3
df[4,]=df4

colnames(df)<-c("p-valeurs/less - Nouvelles Variables")
row.names(df)<-colnames(don.groupe[,2:5])
df
```

Les tests "less" and "greater" n'ont pas ajouté de nouvelles informations concernant la différence significative. Ils ont juste précisé que les résultats de la pédagogie P2 étaient meilleurs dans la variable audela.

### Visualisation de données significativement différentes

```{r}
par(mfrow=c(2,3))
# T72
T72 <- rbind(table(dataPropreP1$T72),table(dataPropreP2$T72))
barplot(T72, beside = T, col = c("blue", "green"), main="T72 : P1<P2")

# T81
T81 <- rbind(table(dataPropreP1$T81),table(dataPropreP2$T81))
barplot(T81, beside = T, col = c("blue", "green"), main="T81 : P1>P2")

# T87
T87 <- rbind(table(dataPropreP1$T87),table(dataPropreP2$T87))
barplot(T87, beside = T, col = c("blue", "green"), main="T87 : P1>P2")

par(xpd=TRUE)
legend(4.12,-22.1,c("P1", "P2"), fill =  c("blue", "green") )

# T88
T88 <- rbind(table(dataPropreP1$T88),table(dataPropreP2$T88))
barplot(T88, beside = T, col = c("blue", "green"), main="T88 : P1>P2")

# T89
T89 <- rbind(table(dataPropreP1$T89),table(dataPropreP2$T89))
barplot(T89, beside = T, col = c("blue", "green"), main="T89 : P1>P2")

# audela
tt<-table(don.groupeP2$audela)
tt["5"]=0
tt1=tt
for (i in 6:12){
  tt1[6]=tt[13]
  tt1[i+1]=tt[i]
}
names(tt1)<-c(0:12)

audela <- rbind(table(don.groupeP1$audela),tt1)
barplot(audela, beside = T, col = c("blue", "green"), main="audela : P1<P2")

mtext("Visualisation de données significativement différentes", side = 3, line = -14, outer = TRUE)
```

##	Arbre de regression
# Conclusion
	
	


