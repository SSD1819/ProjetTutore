---
header-includes: #allows you to add in your own Latex packages
- \usepackage{float} #use the 'float' package
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage[T1]{fontenc}
- \usepackage{lmodern}
- \floatplacement{figure}{H} #make every figure with caption = h
output:
  pdf_document:
    fig_caption: yes
---

 

\begin{titlepage} 

    \newcommand{\HRule}{\rule{\linewidth}{1mm}}  

  \vspace*{1cm} 


\begin{center} 

\textsc{\LARGE Université Grenoble-Alpes }\\[1.5cm] 

\end{center} 

  \vspace*{2cm} 


\HRule\\ 
    \begin{center} 
    
    {\LARGE\bfseries Etude comparative des pédagogies conventionnelle et Montessori en apprentissage des mathématiques de niveau moyenne section de maternelle}\\[0.4cm]  

    \end{center} 

    \HRule\\[0.7cm] 

     

\begin{flushleft} 

            \large 

            \textbf{Auteurs}\\ 

            Azat \textsc{Aleksanyan}\newline Lucas \textsc{Chabeau}\newline Matthieu \textsc{François}\newline Etienne \textsc{Hamard} 

\end{flushleft} 

         

\begin{flushright} 

            \large 

            \textbf{Tuteurs}\\ 

 Marie-Caroline \textsc{Croset}  \\ Adeline \textsc{Leclerc-Samson}

\end{flushright} 
\vspace*{3cm} 


\begin{center}
\textbf{\large 24 avril 2019} 
\end{center}


\end{titlepage} 

 

\newpage
#Remerciements

Nous tenons à remercier particulièrement Madame Adeline Leclercq-Samson et Madame Marie-Caroline Croset pour leur aide, leur disponibilité et leur écoute tout au long du projet.
Nous remercions aussi le CNRS pour la confiance qu'ils nous ont accordé avec ce projet.

\newpage


\renewcommand{\contentsname}{Table des Matières}
\tableofcontents

<!-- Options générales des chunks -->
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, include = FALSE)
```

<!-- Activation des packages nécéssaires et importation des données nécéssaires -->
```{r}
#### Require des packages ####
require(FactoMineR)
require(reshape)
require(ROCR)
require(pROC)
require(ClustOfVar)
require(rpart)
require(rpart.plot)
require(corrplot)
require(ggplot2)
require(rpart)
require(rpart.plot)
require(randomForest)
# require(glmm)

#### Importation des variables nécessaires ####
# load("../export/glmm.RData")
load("../export/ACP.RData")
load("../export/ACM.RData")
load("../export/ACM-datavec.RData")
load("../export/Classif_Pedagogie.RData")
load("../export/classif_questions.RData")
load("../export/New_Variables.RData")
load("../export/arbre_deci.RData")
load("../export/Tests_Stat.RData")
load("../export/graphexplo.RData")
load("../export/importation.RData")
load("../export/rocglm.RData")
load("../export/arbre_deci2.RData")
```

# Introduction

Le programme de notre 1ère année de Master prévoit un projet tutoré faisant appel à nos compétences acquises en statistique et en sciences des données. C'est dans ce contexte que nous avons travaillé en collaboration avec Marie-Caroline Croset et Adeline Leclercq-Samson sur un sujet mêlant sciences cognitives, statistique et fouille de données.

Depuis 4 ans, une equipe de chercheurs de l'institut des sciences cognitives (ISC) de Lyon a testé les capacités en mathématiques des élèves d'une école maternelle située dans une zone REP+ (Réseau d'éducation prioritaire) de l'agglomération Lyonnaise. Une partie de ces élèves ont suivi une méthode d'éducation conventionnelle et les autres ont suivi des enseignements suivant la méthode Montessori. Notre objectif est de voir s'il y a ou non une différence entre le niveau en mathématiques des élèves ayant suivi les enseignements conventionnels et ceux ayant suivi les enseignements Montessori.

Nous avons reçu les résultats des tests sous forme de tableurs que nous avons trié pour ne garder que les résultats des élèves de moyenne section. Nous avons ensuite néttoyé nos données et commencé l'étude sur cette population.

#Problématique

Nous allons donc chercher s'il existe ou non une différence de niveau en mathématiques entre des élèves d'écoles Montessoriennes et des élèves d'écoles Conventionnelles.

\newpage

#1. Contexte

Ce projet nous a été proposé par l'Institut des sciences cognitives - Marc Jeannerod spécialisé en neurosciences. L’UMR (Unité Mixte de Recherche) 5304 créée en 2007 est l'un des deux laboratoires de l’Institut des Sciences Cognitives – Marc Jeannerod. L'UMR 5304 est un laboratoire interdisciplinaire qui intègre l'expertise de chercheurs des Sciences de la Vie (psychologie cognitive, neurosciences) et de médecine (pédo-psychiatrie, neuro-pédiatrie) avec celle de chercheurs des Sciences Humaines et Sociales (linguistique computationelle et théorique et philosophie) pour étudier la nature et la spécificité de l'esprit humain.

##1.1 Les besoins d'un changement éducatif

 Le député et mathématicien Cédric Villani a publié un rapport pour renforcer l'apprentissage des mathématiques à l'école. Les élèves français ont aujourd'hui un niveau insuiétant dans cette discipline. Pourtant, jusqu'en 1985, l'enseignement des mathématiques en France était reconnu comme l'un des meilleurs. L'étude internationale "Trends in International Mathematics and Science Study" (TIMSS) 2015 qui mesure les performances en mathématiques et en sciences des élèves en fin de CM1 classe la France dernière des pays de l'Union européenne. Elle obtient même un score en dessous de la moyenne internationnale. Pour mettre un terme à cette tendance inquiétante de la dégradation du niveau des élèves français en mathématiques, le gouvernement est maintenant ouvert à de nouvelles pédagogies pour l'enseignement des mathématiques.
 
##1.2 Les pedagogies étudiées

\begin{description}
	\item[Pédagogie Montessori :] 

La pédagogie Montessori est une méthode d'éducation créée en 1907 par Maria Montessori.\newline
	La pédagogie se base sur quelques principes :\newline
	-\textbf{La liberté} :  les enfants sont libres de choisir l’activité qu’ils souhaitent faire parmi celles qui leur sont proposées.\newline
	-\textbf{L’autodiscipline} : les enfants sont invités à repérer eux-même leurs erreurs.\newline
	-\textbf{L’action en périphérique} : les professeurs vont préférer agir sur l'environnement de l'enfant plutôt que directement sur lui. Ils vont chercher à inciter l'enfant à faire une activité plutôt que de directement lui demander de faire cette activité.\newline
	-\textbf{Le respect du rythme de chacun} : Le rythme de l'enfant est respecté tant qu'il est concentré.\newline
	-\textbf{L’apprentissage par l’expérience} : Favoriser la pratique pour s'approprier un concept.\newline
	-\textbf{L’activité individuelle} : La plupart des activités se font en individuel.\newline
	-\textbf{L’éducation, une aide à la vie} : L'éducation est faite pour préparer l'enfant à une vie dans une société harmonieuse basée sur le respect de l'autre.\newline

\item[Pédagogie conventionnelle :]

La pédagogie conventionnelle (celle que nous connaissons aujord'hui dans nos écoles publiques) est celle du modèle transmissif. Selon le triangle pédagogique de Jean Houssaye, cette pédagogie privilégie la relation entre l'enseignant et le savoir. Autrement dit, l'enseignant expose un savoir sous forme de cours magistral, généralement suivi d'exercices ou/et de leçons à apprendre. L'élève doit intégrer et appliquer le savoir exposé par l'enseignant.


\end{description}

##1.3 Présentation des données de départd

Notre jeu de données est composé de trois fichiers Excel (.xlsx), avec les résultats de chaque promotion au test cognitif mis en place par l'équipe de recherche de l'institut des sciences cognitives. Un quatrième fichier du même acabit pour l'année 2018/2019 nous est parvenu au milieu de l'étude.
    \begin{description}
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2015/2016.
    \item[MathsJetons\_2015-2016.xlsx :] Pour l'année 2016/2017.
    \item[MathsJetons\_2016-2017.xlsx :] Pour l'année 2017/2018.
    \item[Jetons2019.xlsx :] Pour l'année 2018/2019.
    \end{description}
    Chaque jeu de données représente les résultats questions par questions (en comptant les sous-questions) des élèves  ainsi que leurs catégories pédagogiques et des informations telles que l'encadrant, le niveau scolaire, la langue natale, l'âge, le type de classe (mélangé entre plusieurs section ou pas), l'année de passage du test et leur école.
    Il y à 10 questions divisées en sous questions, ce qui fait un total de 34 réponses. Chaque question est indépendante et pour répondre à la sous question suivante il faut une bonne réponse à la sous-question précédente, sauf pour la question 4, toutes ses sous-questions sont indépendantes. Une bonne réponse correspond à un 1 et une mauvaise réponse à un 0, sauf pour la réponse à la question 1 qui est la valeur de comptage maximale de l'enfant.
Ici les élèves viennent tous d'une ecole située en REP+. 

##1.4 Nettoyage des données 

Les données ayant déjà été travaillées lors d'un précédent stage, le travail de nettoyage nécessaire n'a pas été excessif. Il nous a fallu tout de même renommer certaines variables pour les rendre plus lisibles et cohérentes entre elles, supprimer certaines questions car elles n'avaient été posées qu'à certaines classes... 
Les questions étant posées de manière à ce qu'au sein d'une même tache, il faille réussir les questions dans l'ordre pour passer à celles plus dures nous avions beaucoup de valeurs manquantes dès qu'une question était un peu difficile. Nous avons donc décidé de changer ces valaurs manquantes et les considérer comme une question que l'élève n'aurait pas réussie (donc remplacer NA par 0). Et pour ne pas passer à coté de l'information : "n'a pu aller plus loin", nous avons créé deux jeux de données : un vectoriel (chaque question devient le regroupement des résultats au sous questions. ex : Q2.1 = 1; Q2.2 = 0 devient Q2 = 10), un composé de scores correspondant à la somme des questions au sein d'une même tâche (pour le même exemple que le jeu de données "vectoriel" nous aurions Q2 = 1+0 = 1).

##1.5 Recodage des variables

Afin de ne pas influencer notre jugement sur nos résultats, nous avons dans un premier temps décidé de rendre anonyme le pédagogie enseignée pour chaque classe. Chaque pédagogie fut donc renommée en "P1" et "P2". De ce fait nous n'avons pas pu privilégier une pédagogie plus qu'une autre subjectivement parlant. Aux 3 quarts du projet environ, nous avons reçu les données de nouveaux individus, une cinquantaine, et avons par la même occasion décidé d'enlever cet anonymat. Notre travail étant déjà réalisé, seul l'interprétation sur le jeu de données comportant les nouveaux individus en plus importe.
Comme dit précédemment les questions sont divisées en sous questions, ces questions sont regroupables en groupe : un groupe que nous appellerons "variable au-dela", un groupe "variable outils" puis un groupe "variable objet". Chacun de ces groupes fait appelle à une tache pédagogique en particulier.

\begin{description}
    \item[Variable Au-delà :] est calculée en faisant la somme du nombre de bonnes réponses aux questions 2.3, 3.2, 4.2a, 4.2b, 4.2c, 4.2d, 5.2, 6.2, 8.6, 8.7, 8.8 et 8.9. La première question concernant la capacité à compter loin est prise en compte, les individus sachant compter au-delà de 7 ont un point en plus.
    $audela = 2.3 + 3.2 + 4.2a + 4.2b + 4.2c + 4.2d + 5.2 + 6.2 + 8.6 + 8.7 + 8.8 + 8.9 + \mathbb{1}_{T1>7}$\newline
    \item[Variable Outils :] est calculée en faisant la somme du nombre de bonnes réponses aux questions des taches 4, 5 et 6 soit les questions des taches sur le surcomptage, la création d'une collection et la comparaison de deux collections.
    $outils = 4.1a + 4.1b + 4.1c + 4.1d + 4.2a + 4.2b + 4.2c + 4.2d + 5.1 + 5.2 + 6.1 + 6.2$\newline
    \item[Variable Objet :] est calculée en faisant la somme du nombre de bonnes réponses aux questions des taches 1, 2, 3 et 8 soit les questions des taches sur la capacité à savoir compter, à dénombrer une collection et à constituer une collection d'objets. La question 1 est gérée par paliés. Nous avons séparé les individus en 5 groupes : ceux qui savent compter jusqu'à 3, puis de 4 à 7, de 8 à 10, de 11 à 16, enfin ceux qui savent compter au delà de 16. Respéctivement pour chaque catégorie nous leur avons donné un score de 0, 0.3, 0.6, 0.9 et 1.2.
    $objet = 1.1 + 1.2 + 2.1 + 2.2 + 3.1 + 3.2 + 8.1 + 8.2 + 8.3 + 8.4 + 8.5 + 8.6 + 8.7 + 8.8 + 8.9 + \mathbb{1}_{T1 \in [0;3]}*0 + \mathbb{1}_{T1 \in [4;7]}*0.3 + \mathbb{1}_{T1 \in [8;11]}*0.6 + \mathbb{1}_{T1 \in [12;16]}*0.9 + \mathbb{1}_{T1 >16}*1.2 $\newline\newline
\end{description}

\newpage

#2. Méthodologie

Afin de répondre au mieux à notre problématique nous avons fait le choix d'utiliser plusieurs méthodes statistiques différentes pour analyser nos données. Nous avons dans un premier temps utilisés deux méthodes qui permettent de résumer l'information globale du jeu de données : l'analyse factorielle, et la classification ascendante hiérarchique (pour faire des regroupements de variables). Puis dans un but prédictif nous avons utilisé la régression logistique mixte, la régréssion linéaire mixte et les forêts aléatoires. Plusieurs tests statistiques ont été réalisés en parallèle.

##2.1 Analyse factorielle

Les méthodes d'analyse factorielle que nous avons utilisées ici sont l'analyse des correspondances multiples (ACM) et l'analyse en composantes principales (ACP), qui sont des méthodes de synthétisation du nombre de dimensions pour les données qualitatives et quantitatives. Cela nous permet d'appréhender plus rapidement le jeu de données, et avoir une première idée de ce qui différencie les individus entre eux (ou ce qui les rapproche).
L'ACM permet dans un nuage à N dimensions, en cherchant les axes orthogonaux qui maximisent la variance entre les individus, de résumer ces N dimensions en 4 voire 5 dimensions.
l'ACM a été réalisée sur les données vectorisées (regroupement des réponses aux sous-questions en un vecteur par question, question 1 exclue), celles ci ont été prises comme variables actives (celles qui définissent le placement des individus sur le graphe) et les variables portant sur la pédagogie, la question 1, et l'âge en illustratives (ajoutée après le placement des individus sur le graphe).
Le principe était le même pour l'ACP qui a été faite ensuite.

##2.2 Classification Ascendante Hiérachique

N'ayant aucune information au préalable sur le thème des questions, leur regroupement...etc Mais sachant que certaines questions faisaient appelle aux mêmes compétences. Nous avons utilisé une variante de la classification ascendante hiérarchique (CAH) afin de partitionner nos variables. Nous avons aussi utilisé la CAH classique qui consiste à regrouper les individus selon leur points communs cela en partant d'une inertie interclasse maximale (inertie = somme des variances), pour arriver à une inertie interclasse de 0. Nous avons utilisé la CAH classique afin de partitionner nos individus dans un but descriptif.

##2.3 Arbre de regression 

L'arbre de régression est une technique d'apprentissage supervisé, qui permet en analysant un grand nombre de données, de prédire une variable à expliquer. Ils sont beaucoup utilisés dans le domaine du marketing, et plus récemment dans le domaine du machine learning (apprentissage automatique).
Dans un premier temps il s'agit d'exprimer la variable à expliquer en fonction d'un maximum de variables explicatives, puis d'élaguer l'arbre afin de minimiser l'erreur, soit l'écart entre la valeur prédite et la valeur réelle. Cela revient donc à faire une régression logistique sur les données, puis d'appliquer l'algorithme de construction d'arbre à partir des résultats.

##2.4 Modèle linéaire mixte

Les modèles mixtes linéaires sont une extension des modèles linéaires simples permettant des effets fixes et aléatoires. Ils sont particulièrement utilisés lorsqu'il n'y a pas d'indépendance dans les données, telles qu'elles résultent d'une structure hiérarchique. 

$y_{kj}=\beta_0+\beta_1x_1+...+\beta_jx_j+\beta_k+\varepsilon_{ij}$ sachant $k:k_{ieme}\ groupe \ de \ l'individu$ ; $j:j_{ieme}\ variable$

##2.5 Régression logistique avec effet mixte

Un GLMM (pour Generalized Linear Mixed Models) est dit “mixte”, car il comporte au moins un effet dit “fixe” (la variable dont on souhaite évaluer l’effet, ici les *Pédagogie*, *Age* et *Année Scolaire*) et au moins un effet dit “aléatoire” (la variable de regroupement, ici *newClasse* ou *Group*). Les effets aléatoires ne sont pas évalués, ils servent seulement à indiquer au modèle que les données ne sont pas indépendantes pour une boite donnée. C’est ce qui permet à la déviance résiduelle d’être bien estimée, et ainsi à l’erreur standard des paramètres de ne pas être biaisée, et aux final d’obtenir des résultats fiables.

$P_k(1|X)=\frac{e^{\beta_0+\beta_1x_1+...+\beta_jx_j+\beta_k+\varepsilon_{ij}}}{1+e^{\beta_0+\beta_1x_1+...+\beta_jx_j+\beta_k+\varepsilon_{ij}}}$ sachant $k:k_{iem}\ groupe \ de \ l'individu$

\newpage

#3. Analyse exploratoire

##3.1	Analyse Préliminaire

```{r include=TRUE, fig.cap="Réussite à chaque question par pédagogie"}
ggplot(md.dfpropre, aes(x = variable, fill = value)) + 
  geom_bar(position = "fill",width = 0.7) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
  # scale_fill_manual(values=c(rep("#999999",28),rep("#E69F00",28)))
```

Le graphique précédent montre la proportion de bonnes et de mauvaises réponses par question et par pédagogie. On peut voir que l'ecart entre les deux pédagogies est plus ou moins important selon les questions, mais ce n'étant pas toujours la même pédagogie qui est supérieure à l'autre, cela semble équilibré globalement. Excepté pour les dernières questions, à partir de la question 8.4, la pédagogie Montessorienne est toujours devant la Conventionnelle.

```{r include=TRUE, fig.cap="Score total par année par pédagogie"}
ggplot(df, aes(x=Annee,y=score,fill=Pedagogie)) + 
  geom_boxplot() +
  scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))
```

En ne regardant que certaines années on peut voir clairement une différence entre la pédagogie montessorienne et la pédagogie conventionnelle vis à vis du nombre de bonnes réponses. Toutefois lorsqu'on regarde la vue d'ensemble, on peut voir que selon les années, une fois la pédagogie montessorienne est supérieure à la conventionnelle, parfois c'est l'inverse. On peut donc s'attendre à ce qu'on ne puisse pas prédire quelle pédagogie permet d'obtenir un meilleur score global.

```{r include=TRUE, fig.cap="Score total par pédagogie par classe"}
ggplot(df, aes(x=Pedagogie,y=score,fill=classe)) + 
  geom_boxplot() +
  scale_fill_manual(values=col)
```

De plus il semblerait que la classe dans laquelle se trouve l'individu agisse sur le résultat de l'élève. Comme le montre le graphique précédent, la répartition des résultats totaux varie énormément d'une classe à l'autre.
Enfin, après réalisation d'un test de Chi2 entre chaque question et la variable concernant le groupe des élèves, on peut observer une dépendance entre leur réussite et le groupe associé.


```{r include=TRUE, fig.cap="Score par question par âge"}
ggplot(dp.age, aes(x=variable,y=AgeNum,fill=value)) + 
  geom_boxplot()
```
Enfin le graphique précédent montre que l'âge semble avoir une influence sur la réussite ou non d'une question, et ce, quelque soit la pédagogie enseignée.

Il faudra donc par la suite tenir compte de ces trois facteurs, comme des variables qui peuvent avoir un effet sur la réussite de l'élève en parallèle de la pédagogie enseignée.

##3.2	Multivariée

Afin de traiter l'information présente dans le jeu de données de la meilleure façon, nous avons procédé à 2 analyses multivariées : 1 sur le jeu de données qualitatif sous forme de vecteurs, et 1 sur le jeu de données quantitatif sous forme de scores.

###3.2.1 Analyse des Correspondances Multiples

La réalisation d'une ACM comme première approche sur le jeu de données a permis de mieux comprendre ce qui différencie les individus dans notre jeu de données et à la fois d'avoir un premier résultat sur la différence entre les deux pédagogies selon cette méthode.

```{r include=TRUE, fig.cap="Graphe des modalités sur le plan principal"}
plot.MCA(res.mca.globale,invisible = "ind",cex=0.7,selectMod =  "contrib 15")
```

Le graphe précédent représente les 15 modalités qui contribuent le plus au placement des individus sur le plan principal. On peut donc voir que la dimension 1 oppose des modalités qui concernent la réussite à une question (avec un "_1" à la fin), à droite, à des modalités qui concernent l'échec d'une question (avec un "_0"), à gauche. Plus un élève réussira le questionnaire, plus il se trouvera à droite sur le graphe des individus. Cette interprétation est confirmée par l'ajout de deux individus fictifs : ind_1 et ind_0, qui comportent respectivement des succès à toutes les questions et des échecs à toutes les questions. L'individu ayant réussi en totalité le questionnaire se trouve à droite alors que l'individu ayant raté en totalité le questionnaire se trouve à gauche.
De plus nous pouvons voir que les questions qui discriminent le plus la réussite ou non de l'examen sont les questions concernant l'addition, la soustration et la reconnaissance des chiffres (questions 4 et 8) (de part leur forte contribution). Les caractéristiques qui discriminent le plus les élèves de maternelle seraient donc ces trois capacités.
Toutefois cette première analyse n’aura pas permis de différencier les deux pédagogies, la variable projetée en supplémentaire sur le plan principal n'est pas significativement liée à celui ci.

Dans un second temps nous avons refait une ACM mais cette fois ci sur les données vectorielles. Cela afin de prendre en compte la succession de certaines questions qui se regroupent en "compétences". 

```{r include=TRUE, fig.cap = "Graphe des modalités sur le plan principal"}
plot.MCA(res.mca.vec,invisible = "ind",cex=0.7,selectMod =  "contrib 15")
```

A nouveau la première dimension oppose les individus ayant réussit la totalité (ou la majorité pour certaines) des questions à droite à ceux qui n'en ont réussi aucune à gauche. Nous ne pouvons pas non plus observer de différence significative entre les 2 pédagogies. On peut voir cette fois ci avec plus de précision les questions qui discriminent la réussite au questionnaire. Ce sont Les question 4, 3, 8 et 5. Soit les taches sur la capacité à soustraire et additionner, la constitution d'une collection, la reconnaissance des chiffre et la création d'une collection équipotente.

Dans ces deux cas nous avons pu aussi observer un lien significatif entre les variables qualitatives, portant sur les réponses à la question 1 et l'âge de l'élève, et le placement des individus sur la première dimension. En conséquent on peut dire qu'il existe un lien entre la réussite à l'examen et le fait qu'un enfant sache compter "loin" et dans une moindre mesure, qu'il soit âgé.

Enfin nous avons voulu voir si en classifiant les individus suite à l'ACM nous obtenions des groupes d'individus propre à une pédagogie ou non. Pour cela nous avons utilisé la classification ascendante hiérarchique (CAH).

```{r include=TRUE,fig.cap = "Diagramme des gains d'inertie"}
plot.HCPC(res.hcpcmca,choice = "bar")
```

Nous pouvons observer un "saut" à la troisième classe, donc nous faisons le choix de retenir trois classes pour la CAH. Mais leur composition ne montre aucune sureprésentation d'une pédagogie plus que l'autre. Le test de chi2 entre la variable concernant la pédagogie et celle concernant la classe n'est pas significatif. Une fois de plus cela ne permet donc pas de montrer une liaison entre la pédagogie et ce qui discrimine nos classe. Au final nous obtenions une classe d'individus qui a une majorité d'échecs, une d'individus qui échouent sur les questions 4.2 (soit une incapacité à additionner ou soustraire au delà de 1), et une qui d'individus qui réussissent globalement.

```{r include=TRUE,fig.cap = "Représentation des classes sur le premier plan de l'ACM"}
plot.HCPC(res.hcpcmca,choice = "map")
```


###3.2.2 Analyse en Composantes Principales

La réalisation d'une ACP faisant suite à l'ACM a pour but d'étudier le jeu de données différemment. En effet nous avons étudié cette fois ci le jeu de données concernant les scores. Soit un jeu de données quantitatif. 
Afin de ne pas perdre d'informations nous avons dans un premier temps observé la matrice des corrélations entre les variables de notre jeu de données. Car plus les variables seront corrélées entre elles, plus l'ACP ne montrera que celles ci.

```{r include=TRUE,fig.cap = "Matrice des corrélations"}
corrplot(m.cor,method = "circle")
```

Nous avons donc fait le choix de regrouper les questions 8 en 2 groupes, aux vues des résultats. Un groupe comprenant les questions 8.1, 8.2 et 8.3, et un comportant les autres questions 8. Reconnaitre les chiffres 1, 3 et 2 n'entrainerait donc pas la reconnaissance des autres chiffres jusqu'à 9 forcément.

```{r include=TRUE, fig.cap = "Cercle des corrélations du plan principal"}
plot.PCA(res.pca.nonindsup,choix = "var",select = "contrib 6")
```

La réalisation de l'ACP nous permet donc de voir que les individus se diffèrent sur la première dimension selon les questions sur le dénombrement d'une collection, la constitution d'une collection et la reconnaissance des chiffres (2,3, et 8). Alors que la dimension 2 les différents selon la corrélation négatives des questions sur la comparaison de deux collections et sur la réunion de deux collections (7.2 et 6.2). 
A nouveau nous n'observons pas de lien significatif entre la pédagogie enseignée et le placement des individus sur les axes factoriels.

##3.3 Classification Ascendante Hiérarchique des variables

N'ayant au début de notre analyse, aucune information sur le thème des questions, leur regroupement...etc Mais sachant que certaines questions faisaient appel aux mêmes compétences. Nous avons utilisé une variante de la classification ascendante hiérarchique (CAH) afin de partitionner nos variables. La CAH est une méthode de classification qui permet de regrouper des individus sein d’une même classe et qu'ils soient le plus semblables possible tandis que les classes soient elles, le plus dissemblables possible. 

Nous allons appliquer cette méthode sur les jeux de données en isolant les pédagogies pour comparer les regroupements.

Procédons d'abord à l'isolation de la Pédagogie 1.

```{r, include=TRUE,fig.cap="Dendogramme des donnees generales de la pedagogie P2"}
# par(mfrow=c(1,2))
plot(cahG.P1, main="Dendogramme des donnees generales \n de la pedagogie P1")
rect.hclust(cahG.P1,6)


```

Ici X.quanti correspond a T1.
Nous pouvons observer ici plusieurs regroupement redondant. Le regroupement des questions T81, T82 et T83 et celui des questions T84, T85, T86, T87, T88, T89.
Les question T1, T2 et T3 sont aussi fortement attirées, on retrouve en partie la variable "Objet".






Comparons maintenant avec les regroupements de la Pédagogie 2.

```{r, include=TRUE, fig.cap="Dendogramme des donnees generales de la pedagogie P2"}
plot(cahG.P2, main="Dendogramme des donnees generales \n de la pedagogie P2")
rect.hclust(cahG.P2,6)
```

<!-- Audela: 2.3, 3.2, 5.2, 6.2, 8.6, 8.7, 8.8, 4.a,b,c,d, -->
<!-- Outil: 4, 5, 6 -->
<!-- Objet: 1, 2, 3 et 8 -->


Nous observons en regroupement des questions T82, T83, T84, T85, T86, T87, T88, T89. La T81 étant séparée du reste. On voit aussi apparaitre deux couples de questions, T61 et T62 ainsi que T51 et T52.
Ici nous ne voyons aucunes variable prédéfinie ressortir véritablement.


On retrouve plus de similarités entre les classification de la pédagogie 2 qu'entre celles de la Pédagogie 1. 
Et on remarque que les regroupement qui sont stables entre les changements de jeux de données sont principalement ceux liés aux sous questions de la T8.
Pour résumer, les groupes qui ressortent sont pour la Pédagogie 1: (T81, T82 , T83), (T84, T85, T86, T87, T88, T89) et (T1,T2, T3)
Et pour la Pédagogie 2: (T82, T83, T84, T85, T86, T87, T88, T89), (T61, T62) et (T51, T52).

Seul la variable 'Objet' est en parti retrouvée et seulement dans le cas de la Pédagogie 1.

\newpage

#4. Modélisation linéaire des résultats à chaque question.

Nous avons voulu modéliser les résultats des élèves à chaque question en fonction de ses caractéristiques individuelles (y compris la pédagogie suivie bien-sûr) pour voir si la pédagogie a un effet sur la réussite au test. Les résultats de certaines questions sont binaires (1 pour réussite, 0 pour échec), la plupart sont concernées  (toutes sauf la question 1 qui consiste à faire compter l'enfant le plus loin possible). Les résultats à l'autre question prennent des valeurs continues : la question 1 est dans ce cas mais aussi les résultats ques nous avons construit en regroupant des questions (au-delà, objet et outils qui sont expliqués en **1.5**).\newline

Intuitivement, nous sommes d'abord tentés de modéliser les résultats binaires par une régression logistique et les résultats continus par une régression linéaire. Mais, notamment grâce à l'analyse préliminaire faite précédemment, nous soupçonnons un effet aléatoire de la variable classe sur la réponse des élèves, c'est à dire que selon la classe (pas la pédgogie suivie) dans laquelle se trouve l'élève sa réponse sera différente. Cet effet semble être aléatoire (elle n'est pas modélisable linéairement). Il existe justement des méthodes satistiques spécialement faites pour ces cas : il s'agit des **modélisations mixtes**. Ces dernières prennent bien en compte les effets aléatoires tels la différence de résultats selon la classe de nos élèves.\newline

Nous avons donc réalisé nos modélisations avec des **modèles linéaires mixtes** (pour les résultats continus) et des **regression logistique mixte** (pour les résultats binaires).


##4.1 Modélisation des questions à résultat continu par modèle linéaire mixte

L'analyse exploratoire nous laisse en effet bien penser que les scores des élèves sont répartis différemment selon la classe dans laquelle il étudie, sa promotion et son âge. Mais seule la classe a été retenue comme effet aléatoire. L'âge a lui un effet fixe, la promotion et la pédagogie de l'élève n'ont finalement pas d'effet significatif (il s'agirait d'un effet fixe s'il était significatif).

Nous avons donc réalisé nos regressions linéaires mixtes sur les regroupements de variable en mettant la variable sur le groupe (la classe) comme effet aléatoire. Et les variables sur la pédagogie, l'âge et la promotion et comme effets fixes.

Pour la modélisation de chaque regroupement de questions (au-delà, objet, outils), nous obtenons bien la présence d'un effet aléatoire, mais apres selection de variables et tests statistique, seul l'âge a un effet fixe significatif sur nos variables à expliquer.

Enfin nous avons rajouté un dernier modèle sur la question concernant la capacité à compter loin. L'effet aléatoire est important, mais est justifié par l'ordre de grandeur de la variable en question.

$$
\begin{aligned}
Au-delà = -6.19 + 2.493*age +\beta_k+\varepsilon_{ij}\\
Objet = -2.88 + 1.90*age +\beta_k+\varepsilon_{ij}\\
Outils = -0.594 + 0.741*age+\beta_k+\varepsilon_{ij}\\
Q1 = -9.554 + 4.667*age +\beta_k+\varepsilon_{ij} \\
k:k_{ieme}\ groupe \ dans \ lequel \ est \ l'individu \ ; \ j:j_{ieme}\ variable
\end{aligned}
$$
avec les p.value suivantes pour le coefficient de l'âge :
    - pour le modèle d'Au-dela : 0.0006 et les coefficients de l'effet aléatoire ont un écart type de 0.4741162
    - pour le modèle d'Objet : 0.0007 et les coefficients de l'effet aléatoire ont un écart type de 2.433568e-07 (il ne semble pas que l'effet aléatoire soit nécessaire pour cette variable)
    - pour le modèle d'Outils : 0.0257 et les coefficients de l'effet aléatoire ont un écart type de 0.05115118
    - pour la question 1 : 0.0436 et les coefficients de l'effet aléatoire ont un écart type de 0.5511588

Pour résumer, nous n'avons pas pu modéliser la réussite à certains regroupements de tâches en fonction de la pédagogie enseignée. Toutefois nous observons qu'il est possible de les modéliser en fonction de l'âge de l'élève en prenant l'éffet groupe en compte.


##4.2 Modélisation des questions à résultat binaire par regression logistique mixte

N'ayant pas eu de résultats concernant la pédagogie lors de la modélisation linéaire mixte précédente, nous avons affiné notre modélisation en réalisant une regression logistique mixte sur les questions à résultat binaire.

Les principaux résultats coïncident en partie avec les résultats précédents. La pédagogie n'est significativement liée qu'à 2 questions, la question Q5.1 (création d'une collection équipotente), qui a un effet aléatoire **groupe** significatif, et la Q8.9 (reconnaissance d'un chifffre particulier. **Attention !** Les questions 8.1 à 8.8 portaient sur la même tématique mais avec un autre chiffre), en complément d'un effet fixe de l'âge. De plus à nouveau plusieurs variables sont modélisables à partir de l'âge de chaque individu (voir annexe chaque modèle). 

$$
\begin{aligned}
Q51 : P(1|Montessori) = \frac{e^{-1.1884+-0.8875+\beta_k+\varepsilon_{ij}}}{1+e^{-1.1884+-0.8875+\beta_k+\varepsilon_{ij}}}\\
Q89 : P(1|Montessori) = \frac{e^{-6.358+0.6404+1.287*age+\beta_k+\varepsilon_{ij}}}{1+e^{-6.358+0.6404+1.287*age+\beta_k+\varepsilon_{ij}}}\\
k:k_{ieme}\ groupe  \ dans \ lequel \ est \ l'individu \ ; \ j:j_{ieme}\ variable
\end{aligned}
$$
Avec un écart type pour les coefficients de l'effet aléatoire groupe de la Q51 de 0.1416281 et pour la Q89 de 0.1107895

- Le coefficient de l'âge a une p.value de 0.00617 pour la Q89.

- Le coefficient de la Pédagogie a une p.value de 0.0376 pour la Q51 et de 0.02658 pour la Q89.


Il y a donc une prédisposition à réussir la question T89 pour chez les élèves ayant suivant la pédagogie Montessorienne.
Inversement pour la T51 qui est en faveur de la pédagogie Conventionnelle.

Etant limité par les packages disponible de R, nous n'avons pas pu faire les courbe ROC de ces deux régressions logistiques mixtes.

#5. Forêt d'arbres décisionnels 

Les Forêt d'arbres décisionnels sont une méthode d'apprentissage automatique de régression et de classification basée sur la construction d'une multitude d'arbres de décision. Les forêts d'arbres décisionnels utilisent la méthode du bagging. Le bagging consiste à prendre un jeu de données $\mathit{D}$ de taille $n$, et créer $m$ nouveaux jeux de données $\mathit{D_{i}}$ de taille $n'$ en échantillonnant $\mathit{D}$ uniformément et avec remise. Ensuite l'algorithme crée à partir de chaque échantillon $\mathit{D_{i}}$ un arbre de décision pour ensuite agréger ces arbres et obtenir un modèle stable. \newline 

Pour prédire une variable quantitative l'agrégation se fait par la moyenne : $\mathit{G(x)}=\frac{1}{m}\sum_{i=1}^{m} \mathit{G_{i}(x)}$ .

Et pour prédire une variable qualitative on procède à une agrégation par le vote : $\mathit{G(x)}=$ Vote majoritaire $(\mathit{G_{1}(x)},..., \mathit{G_{m}(x)})$ où $\mathit{G_{1}(x)}$ représente un modèle entrainé sur un ensemble $\mathit{D_{i}}$. 

Nous avons donc appliqué cet algorithme sur deux jeux de données, le jeu de données contenant les variables regroupées et le jeu de données de base contenant toutes les questions une à une.  

Nous avons ici la matrice de confusion. Cette matrice nous donne en ligne les données observées et en colonnes les données prédites. Il y a 64 individus issus de la pédagogie Conventionnelle ayant été bien classés et 32 individus ayant été mal classés et considérés comme des Montessori. Ce qui nous donne un taux de bonne prédiction pour les individus de la pédagogie Conventionnelle de 33%. 

Pour la pédagogie Montessori, 26 ont été bien classés et 41 ont été classés en Conventionnelle à tort. On a donc une minorité de bonne prédiction. Nous ne pouvons pas obtenir une prédiction efficace grâce à ce modèle.  

```{r, include=TRUE} 
model.rf1$confusion  
``` 

Maintenant voyons pour le jeu de données avec les questions générales. 

La matrice de confusion nous indique qu'il y a 24% de mauvaises prédictions pour la catégorie Conventionnelle et 76% de mauvaises prédictions pour la catégorie Montessori 

````{r, include=TRUE} 
model.rf$confusion  
``` 

#Conclusion

Afin de d'étudier les éventuelles différences ou non en mathématiques entre les élèves suivants une pédagogie Montessoriennes et et ceux suivants Conventionnelle, nous avons commencé par une brève étude exploratoire permettant de comprendre nos données et de repérer les possibles liens entre les variables. Par la suite une analyse prédictive sur les réponses aux questions en fonction de la pédagogie aurait pu permettre de différencier ces deux pédagogies. Toutefois, les résultats de cette analyse sont peu concluants. Seuls 2 modèles différencient les 2 pédagogies : la modélisation des réponses aux questions concernant la création d'une collection équipotente et la reconnaissance d'un chiffre particulier. 
Il serait intéressant de continuer cette étude avec un nombre d'individus plus important voir si de nouveaux liens apparaissent.

<!-- #Annexes -->

<!-- T21 : -->
<!-- T21m <- glmm(T21 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T21mm) -->
<!-- ``` -->

<!-- T21mm <- glmm(T21 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T21mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T22 : -->
<!-- T22m <- glmm(T22 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T22m) -->
<!-- ``` -->

<!-- T22mm <- glmm(T22 ~ age , -->
<!--                     random = list(~ 0 + newClasse), -->
<!--                     varcomps.names=c("newClasse"),data=don.reg, -->
<!--                     family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T22mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T23 : -->
<!-- T23m <- glmm(T23 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T23m) -->
<!-- ``` -->

<!-- T23mm <- glmm(T23 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T23mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T31 : -->
<!-- T31m <- glmm(T31 ~ Pedagogie + age , -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T31m) -->
<!-- ``` -->

<!-- T31mm <- glmm(T31 ~ age, -->
<!--                     random = list(~ 0 + newClasse), -->
<!--                     varcomps.names=c("newClasse"),data=don.reg, -->
<!--                     family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T31mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T32 : -->
<!-- T32m <- glmm(T32 ~ Pedagogie+age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T32m) -->
<!-- ``` -->

<!-- T32mm <- glmm(T32 ~ age, -->
<!--                     random = list(~ 0 + newClasse), -->
<!--                     varcomps.names=c("newClasse"),data=don.reg, -->
<!--                     family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T32mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T41a : -->
<!-- T41amm <- glmm(T41a ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T41amm) -->
<!-- ``` -->

<!-- T41amm <- glmm(T41a ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T41amm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T41b : -->
<!-- T41bm <- glmm(T41b ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41bm) -->
<!-- ``` -->

<!-- T41bmm <- glmm(T41b ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41bmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T41c : -->
<!-- T41cm <- glmm(T41c ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41cm) -->
<!-- ``` -->

<!-- T41cmm <- glmm(T41c ~ Pedagogie, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41cmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T41d : -->
<!-- T41dm <- glmm(T41d ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41dm) -->
<!-- ``` -->

<!-- T41dmm <- glmm(T41d ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T41dmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T42a : -->
<!-- T42am <- glmm(T42a ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T42am) -->
<!-- ``` -->

<!-- T42amm <- glmm(T42a ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T42amm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T42b : -->
<!-- T42bm <- glmm(T42b ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T42bm) -->
<!-- ``` -->

<!-- T42bmm <- glmm(T42b ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T42bmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T42c : -->
<!-- T42cm <- glmm(T42c ~ Pedagogie + age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T42cm) -->
<!-- ``` -->

<!-- T42cmm <- glmm(T42c ~ age, -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T42cmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T42d : -->
<!-- T42dm<- glmm(T42d ~ Pedagogie + age , -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T42dm) -->
<!-- ``` -->

<!-- T42dmm <- glmm(T42d ~ age , -->
<!--              random = list(~ 0 + newClasse), -->
<!--              varcomps.names=c("newClasse"),data=don.reg, -->
<!--              family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T42dmm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T51 : -->
<!-- T51m <- glmm(T51 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T51m) -->
<!-- ``` -->

<!-- T51mm <- glmm(T51 ~ Pedagogie, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T51mm) -->
<!-- ``` -->
<!-- La Pedagogie est significative -->

<!-- T52 : -->
<!-- T52m<-glmm(T52 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T52m) -->
<!-- ``` -->

<!-- T52mm<-glmm(T52 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T52mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T61 : -->
<!-- T61m<-glmm(T61 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T61m) -->
<!-- ``` -->

<!-- T61mm<-glmm(T61 ~ Pedagogie, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T61mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T62 : -->
<!-- T62m<-glmm(T62 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T62m) -->
<!-- ``` -->

<!-- T62mm<-glmm(T62 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T62mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T71 : -->
<!-- T71m<-glmm(T71 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T71m) -->
<!-- ``` -->

<!-- T71mm<-glmm(T71 ~ Pedagogie, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T71mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T72 : -->
<!-- T72m<-glmm(T72 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T72m) -->
<!-- ``` -->

<!-- T72mm<-glmm(T72 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T72mm) -->
<!-- ``` -->
<!-- Aucune variable n'est significative. -->

<!-- T81 : -->
<!-- Impossible de lancer la T81 -->

<!-- T82 : -->
<!-- T82m<-glmm(T82 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T82m) -->
<!-- ``` -->

<!-- T82mm<-glmm(T82 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T82mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T83 : -->
<!-- T83m<-glmm(T83 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->

<!-- summary(T83m) -->
<!-- ``` -->

<!-- T83mm<-glmm(T83 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T83mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T84 : -->
<!-- T84m<-glmm(T84 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T84m) -->
<!-- ``` -->

<!-- T84mm<-glmm(T84 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T84mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T85 : -->
<!-- T85m<-glmm(T85 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T85m) -->
<!-- ``` -->

<!-- T85mm<-glmm(T85 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T85mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T86 : -->
<!-- T86m<-glmm(T86 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T86m) -->
<!-- ``` -->

<!-- T86mm<-glmm(T86 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T86mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T87 : -->
<!-- T87m<-glmm(T87 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T87m) -->
<!-- ``` -->

<!-- T87mm<-glmm(T87 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T87mm) -->
<!-- ``` -->
<!-- L'âge est significatif -->

<!-- T88 : -->
<!-- T88m<-glmm(T88 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T88m) -->
<!-- ``` -->

<!-- T88mm<-glmm(T88 ~ age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T88mm) -->
<!-- ``` -->
<!-- L'âge est significatif (age + pedagogie presque) -->

<!-- T89 : -->
<!-- T89m<-glmm(T89 ~ Pedagogie + age, -->
<!--             random = list(~ 0 + newClasse), -->
<!--             varcomps.names=c("newClasse"),data=don.reg, -->
<!--             family.glmm = binomial.glmm, m=10^4, debug=TRUE) -->
<!-- ```{r include=TRUE} -->
<!-- summary(T89m) -->
<!-- ``` -->
<!-- L'âge + la pédagogie sont significatifs -->



